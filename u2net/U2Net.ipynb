{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext blackcellmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "import pathlib\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import RunningAverage\n",
    "from ignite.contrib.handlers.tqdm_logger import ProgressBar\n",
    "from ignite.handlers import ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split \n",
    "from ignite.metrics import Loss\n",
    "from functools import partial\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('1.3.1', '1.16.3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__, np.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For training versions: ('1.3.1', '1.16.3') was used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data_path\": \"./data/train_size_1024_768\",\n",
    "    \"device\": \"cuda\",\n",
    "    \"test_size\": 0.1,\n",
    "    \"random_seed\": 42,\n",
    "    \"resize\": (512, 384),\n",
    "    \"batch_size\": 4,\n",
    "    \"learning_rate\": 0.0001\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_folder = pathlib.Path(config[\"data_path\"]).resolve() / \"labels\"\n",
    "all_names = [x.name for x in labels_folder.iterdir() if x.is_file()]\n",
    "train_idx, test_idx = train_test_split(\n",
    "    np.arange(len(all_names)),\n",
    "    test_size=config[\"test_size\"],\n",
    "    random_state=config[\"random_seed\"],\n",
    "    shuffle=True,\n",
    ")\n",
    "train_names = [x for i, x in enumerate(all_names) if i in train_idx]\n",
    "test_names = [x for i, x in enumerate(all_names) if i in test_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_input_image(path, out_size, mean):\n",
    "    input_image = Image.open(path).resize(out_size, Image.LANCZOS)\n",
    "    input_array = np.array(input_image, dtype=np.float32)\n",
    "    return input_image, ((torch.from_numpy(input_array) - mean) / 255.0).permute(2, 0, 1)\n",
    "\n",
    "\n",
    "def load_label_image(path, out_size):\n",
    "    label_image = Image.open(path).resize(out_size, Image.NEAREST)\n",
    "    label_array = np.array(label_image)[:, :, 0]\n",
    "    label_array[(label_array <= 128) & (label_array > 0)] = 1\n",
    "    label_array[label_array > 128] = 2\n",
    "    return label_image, torch.LongTensor(label_array)\n",
    "\n",
    "\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path,\n",
    "        file_names,\n",
    "        dataset_mean=(69.2614, 55.9220, 32.6043),\n",
    "        out_size=(512, 384),\n",
    "        load_augumentations=True,\n",
    "    ):\n",
    "        images_folder = pathlib.Path(data_path).resolve() / \"images\"\n",
    "        labels_folder = pathlib.Path(data_path).resolve() / \"labels\"\n",
    "        all_names = file_names\n",
    "        self.all_pairs = [(images_folder / name, labels_folder / name) for name in all_names]\n",
    "        self.out_size = out_size\n",
    "        self.mean = torch.tensor(dataset_mean)\n",
    "        self.all_data = []\n",
    "        self.all_images = []\n",
    "        for input_path, label_path in tqdm(self.all_pairs, desc=\"Loading images to RAM\"):\n",
    "            input_image, input_normalized = load_input_image(input_path, self.out_size, self.mean)\n",
    "            label_image, label_long = load_label_image(label_path, self.out_size)\n",
    "            self.all_data.append((input_normalized, label_long))\n",
    "            self.all_images.append((input_image, label_image))\n",
    "        if load_augumentations:\n",
    "            augumented_folder = images_folder / \"output\"\n",
    "            all_augumented_files = list(augumented_folder.iterdir())\n",
    "            for name in tqdm(all_names, desc=\"Loading augumentations to RAM\"):\n",
    "                input_paths = [\n",
    "                    x\n",
    "                    for x in all_augumented_files\n",
    "                    if f\"_{name}_\" in x.name and not x.name.startswith(\"_groundtruth\")\n",
    "                ]\n",
    "                label_paths = [\n",
    "                    x\n",
    "                    for x in all_augumented_files\n",
    "                    if f\"_{name}_\" in x.name and x.name.startswith(\"_groundtruth\")\n",
    "                ]\n",
    "                pairs = defaultdict(list)\n",
    "                for input_path in input_paths:\n",
    "                    pairs[input_path.name.split(\"_\")[3]].append(input_path)\n",
    "                for label_path in label_paths:\n",
    "                    pairs[label_path.name.split(\"_\")[5]].append(label_path)\n",
    "                for input_path, label_path in list(pairs.values()):\n",
    "                    input_image, input_normalized = load_input_image(input_path, self.out_size, self.mean)\n",
    "                    label_image, label_long = load_label_image(label_path, self.out_size)\n",
    "                    self.all_data.append((input_normalized, label_long))\n",
    "                    self.all_images.append((input_image, label_image))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.all_data[idx]\n",
    "\n",
    "    def get_image(self, idx):\n",
    "        return self.all_images[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = SegmentationDataset(config[\"data_path\"], train_names, out_size=config[\"resize\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SegmentationDataset(\n",
    "    config[\"data_path\"], test_names, out_size=config[\"resize\"], load_augumentations=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Down(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels),\n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Up(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout, bilinear=True):\n",
    "        super().__init__()\n",
    "\n",
    "        # if bilinear, use the normal convolutions to reduce the number of channels\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels // 2, in_channels // 2, kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv = nn.Sequential(\n",
    "            DoubleConv(in_channels, out_channels), \n",
    "            nn.Dropout2d(p=dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # input is CHW\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        # if you have padding issues, see\n",
    "        # https://github.com/HaiyongJiang/U-Net-Pytorch-Unstructured-Buggy/commit/0e854509c2cea854e247a9c615f175f76fbb2e3a\n",
    "        # https://github.com/xiaopeng-liao/Pytorch-UNet/commit/8ebac70e633bac59fc22bb5195e513d5832fb3bd\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, bilinear=True):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "        self.bilinear = bilinear\n",
    "\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128, 0.2)\n",
    "        self.down2 = Down(128, 256, 0.2)\n",
    "        self.down3 = Down(256, 512, 0.2)\n",
    "        self.down4 = Down(512, 512, 0.5)\n",
    "        self.up1 = Up(1024, 256, 0.2, bilinear)\n",
    "        self.up2 = Up(512, 128, 0.2, bilinear)\n",
    "        self.up3 = Up(256, 64, 0.2, bilinear)\n",
    "        self.up4 = Up(128, 64, 0.0, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        logits = self.outc(x)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_loss(logits, true, eps=1e-7):\n",
    "    \"\"\"Computes the Sørensen–Dice loss.\n",
    "    Note that PyTorch optimizers minimize a loss. In this\n",
    "    case, we would like to maximize the dice loss so we\n",
    "    return the negated dice loss.\n",
    "    Args:\n",
    "        true: a tensor of shape [B, 1, H, W].\n",
    "        logits: a tensor of shape [B, C, H, W]. Corresponds to\n",
    "            the raw output or logits of the model.\n",
    "        eps: added to the denominator for numerical stability.\n",
    "    Returns:\n",
    "        dice_loss: the Sørensen–Dice loss.\n",
    "    \"\"\"\n",
    "    num_classes = logits.shape[1]\n",
    "    print(logits.shape)\n",
    "    if num_classes == 1:\n",
    "        true_1_hot = torch.eye(num_classes + 1)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        true_1_hot_f = true_1_hot[:, 0:1, :, :]\n",
    "        true_1_hot_s = true_1_hot[:, 1:2, :, :]\n",
    "        true_1_hot = torch.cat([true_1_hot_s, true_1_hot_f], dim=1)\n",
    "        pos_prob = torch.sigmoid(logits)\n",
    "        neg_prob = 1 - pos_prob\n",
    "        probas = torch.cat([pos_prob, neg_prob], dim=1)\n",
    "    else:\n",
    "        true_1_hot = torch.eye(num_classes)[true.squeeze(1)]\n",
    "        true_1_hot = true_1_hot.permute(0, 3, 1, 2).float()\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "    true_1_hot = true_1_hot.type(logits.type())\n",
    "    dims = (0,) + tuple(range(2, true.ndimension()))\n",
    "    intersection = torch.sum(probas * true_1_hot, dims)\n",
    "    cardinality = torch.sum(probas + true_1_hot, dims)\n",
    "    dice_loss = (2. * intersection / (cardinality + eps)).mean()\n",
    "    return (1 - dice_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SoftDiceLoss(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(SoftDiceLoss, self).__init__()\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        smooth = 1\n",
    "        num = targets.size(0)\n",
    "        print(logits.shape)\n",
    "        probs = F.sigmoid(logits)\n",
    "        m1 = probs.view(num, -1)\n",
    "        m2 = targets.view(num, -1)\n",
    "        intersection = (m1 * m2)\n",
    "\n",
    "        score = 2. * (intersection.sum(1) + smooth) / (m1.sum(1) + m2.sum(1) + smooth)\n",
    "        score = 1 - score.sum() / num\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNet(3,3)\n",
    "model_path = \"./models/unet_W512_H384_8_cel=0.1997969.pth\"\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "model.to(config[\"device\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def improvement_function(testing_evaluator, test_data_loader, trainer):\n",
    "    testing_evaluator.run(test_data_loader)\n",
    "    metrics = testing_evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg loss: {:.3f}\".format(trainer.state.epoch, metrics[\"cel\"]))\n",
    "\n",
    "    return -metrics[\"cel\"]\n",
    "\n",
    "\n",
    "train_data_loader = torch.utils.data.DataLoader(train_dataset, batch_size=config[\"batch_size\"], shuffle=True)\n",
    "test_data_loader = torch.utils.data.DataLoader(test_dataset, batch_size=config[\"batch_size\"], shuffle=False)\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=config[\"learning_rate\"])\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "trainer = create_supervised_trainer(model, optimizer, loss, device=config[\"device\"])\n",
    "evaluator = create_supervised_evaluator(model, metrics={\"cel\": Loss(loss)}, device=config[\"device\"])\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    \"./models\",\n",
    "    f\"unet\",\n",
    "    score_name=\"cel\",\n",
    "    score_function=partial(improvement_function, evaluator, test_data_loader),\n",
    "    n_saved=2,\n",
    "    create_dir=True,\n",
    "    require_empty=False,\n",
    ")\n",
    "\n",
    "trainer.add_event_handler(\n",
    "    Events.EPOCH_COMPLETED, checkpoint, {f\"W{config['resize'][0]}_H{config['resize'][1]}\": model}\n",
    ")\n",
    "\n",
    "RunningAverage(output_transform=lambda x: x).attach(trainer, \"loss\")\n",
    "\n",
    "pbar = ProgressBar(persist=True)\n",
    "pbar.attach(trainer, [\"loss\"])\n",
    "\n",
    "state = trainer.run(train_data_loader, max_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spot_check_model(model, dataset, idx, config):\n",
    "    result = model.forward(dataset[idx][0].unsqueeze(0).to(config[\"device\"]))\n",
    "    probab = nn.Softmax(dim=0).forward(result[0])\n",
    "    result_cuda = probab.argmax(dim=0)\n",
    "    numpy_result = result_cuda.cpu().numpy()\n",
    "    numpy_result[numpy_result == 1] = 128\n",
    "    numpy_result[numpy_result == 2] = 255\n",
    "    return Image.fromarray(numpy_result.astype(\"uint8\"), mode=\"L\"), dataset.get_image(idx)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, true = spot_check_model(model, dataset, 1, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
